\documentclass{beamer}
\usetheme{berlin}
\definecolor{utorange}{HTML}{F77F00}
\definecolor{smokey}{HTML}{4C4D4F}
\definecolor{limestone}{HTML}{F0EDE4}
\definecolor{accent}{RGB}{0,018,147}
\definecolor{darkutorange}{HTML}{a95700}
\definecolor{lightutorange}{HTML}{ffe8d0}

\setbeamercolor*{title}{fg=smokey,bg=limestone}
\setbeamercolor*{author}{fg=smokey}
\setbeamercolor*{institute}{fg=smokey}
\setbeamercolor*{date}{fg=smokey}
\setbeamercolor*{frametitle}{fg=smokey, bg=limestone,}
\setbeamercolor*{structure}{fg=utorange}
\setbeamercolor{normal text}{fg=smokey,bg=white}
\setbeamercolor{alerted text}{fg=utorange}
\setbeamercolor{example text}{fg=smokey}
\setbeamercolor{palette primary}{fg=black, bg=utorange}
\setbeamercolor{palette secondary}{fg=white, bg=utorange}
\setbeamercolor{palette tertiary}{fg=white, bg=darkutorange}

\DeclareMathOperator*{\argmax}{\text{argmax}}
\DeclareMathOperator*{\argmin}{\text{argmin}}
\DeclareMathOperator{\uu}{\mathbf{u}}
\usepackage{tikz}
\usepackage{array}
\usetikzlibrary{calc, shapes, fit}


\title{On Random Graphs and their Evolution}
\author{John McAlister}
\institute[Fefferman Lab]{University of Tennessee - Knoxville}
\date{April 9, 2024}
\begin{document}
\begin{frame}[plain]
    \centering
    \maketitle
    \includegraphics[height=3cm]{images/LogoCenter.jpg}
\end{frame}

\begin{frame}{Erd\H{o}s and R\'enyi}
	\begin{tabular}{c}
	\includegraphics[width = \linewidth]{images/OnRandomGraphs}\\
	\hline \\
	\includegraphics[width = \linewidth]{images/OnTheEvolutionOfRandomGraphs}
	\end{tabular}
\end{frame}

\begin{frame}{Random Graphs}
	\begin{block}{$\Gamma_{n,N}$ - ``GnN"}
		Consider a graph with $n$ labeled vertices and $N$ edges. There are are ${{n\choose 2}\choose N}$ possible graphs. For each of the ${n \choose 2}$ possible edges, select a subset of $N$ to get a unique \textit{labeled} graph
	\end{block}
	
	\begin{block}{$\Gamma_{n,p}$ - ``Gnp"}
		Consider a graph with $n$ labeled edges. Each of the ${n\choose 2}$ edges have a probability $p$ of being included in the graph. The edge number of $\Gamma_{n,p}$ is a $\mathcal{B}({n\choose 2},p)$ random variable
		$$P(|E(\Gamma_{n,p})|=N)={{n\choose 2}\choose N} p^N(1-p)^{{n\choose 2}-N}$$
	\end{block}
\end{frame}

\begin{frame}{$\Gamma_{n,N}$ example}
	$\Gamma_{4,2}\in$:
	\begin{tabular}{ccccc}
		\begin{tikzpicture}
			
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (a)--(b);
			\draw (a)--(c);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
		
			\draw (a)--(b);
			\draw (a)--(d);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
	
			\draw (a)--(b);
			\draw (b)--(c);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};

			\draw (a)--(b);
			\draw (b)--(d);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};

			\draw (a)--(b);
			\draw (c)--(d);
		\end{tikzpicture}\\
		& & & & \\
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (a)--(c);
			\draw (a)--(d);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (a)--(c);
			\draw (b)--(c);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (a)--(c);
			\draw (b)--(d);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (a)--(c);
			\draw (c)--(d);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (a)--(d);
			\draw (b)--(c);
		\end{tikzpicture}\\
		& & & & \\
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (a)--(d);
			\draw (b)--(d);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (a)--(d);
			\draw (c)--(d);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (b)--(c);
			\draw (b)--(d);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (b)--(c);
			\draw (c)--(d);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (b)--(d);
			\draw (c)--(d);
		\end{tikzpicture}
	
	\end{tabular}
\end{frame}

\begin{frame}{$\Gamma_{n,N}$ example}
	Notice that there are only two equivalence classes in the state space of $\Gamma_{4,2}$ under isomorphism
	\begin{figure}
		\centering
		\begin{tabular}{cc}
		$P_3\cup v$&$P_2\cup P_2$\\
		\begin{tikzpicture}
			
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (a)--(b);
			\draw (a)--(c);
		\end{tikzpicture}&
		\begin{tikzpicture}
			\node(a)[circle, fill, inner sep =1.5pt] at (0,0){};
			\node(b)[circle, fill, inner sep = 1.5pt] at(1,0){};
			\node(c)[circle, fill, inner sep = 1.5pt] at(1,1){};
			\node(d)[circle, fill, inner sep = 1.5pt] at(0,1){};
			
			\draw (a)--(d);
			\draw (b)--(c);
		\end{tikzpicture}\\
		$P(\Gamma_{4,2}\sim P_3\cup v)= \frac{4}{5}$&
			$P(\Gamma_{4,2}\sim P_2\cup P_2)= \frac{1}{5}$
	\end{tabular}
\end{figure}

\end{frame}

\begin{frame}{On Random Graphs I}
	Erd\H{o}s and R\'enyi were first interested in the following
	\begin{enumerate}
		\item What is the probability that $\Gamma_{n,N}$ is connected?
		\item What is the probability that the greatest connected component of $\Gamma_{n,N}$ has $n-k$ vertices?
		\item What i the probability that $\Gamma_{n,N}$ should consist of exactly $k+1$ connected components?
	\end{enumerate}
	And in particular they are interested in these probabilities as $n\rightarrow +\infty$. 
	
	
\end{frame}

\begin{frame}{Probability that $\Gamma_{n,N}$ is connected}
	Of course if $N$ is fixed and $n$ grows we can expect that the graph will certainly be disconnected, with $N$ connected components each with 2 vertices (and many isolated vertices). 
	
	Instead they consider $N$ as a function of $n$
	
	\begin{block}{Weak result about connectedness probabilities}
		If $N(n)>\left(\frac{1}{2}+\varepsilon\right)n\log n$ then the probability that $\Gamma_{n,N(n)}$ is connected is one in the limit $n\rightarrow +\infty$ and if $N(n)<\left(\frac{1}{2}-\varepsilon\right)n\log n$ then the probability that $\Gamma_{n,N(n)}$ is connected is zero in the limit $n\rightarrow +\infty$. 
	\end{block}
\end{frame}

\begin{frame}{Probability that $\Gamma_{n,N}$ is connected}
	For a more complete result let $N_c=\lfloor\frac{1}{2}n\log n+cn \rfloor$ and let $A$ be the set of graphs which have a connected component of order $n-k$, and  exactly $k$ isolated points for any $k$. ($\overline{{A}}$ is the complement of this set)
	
	\begin{block}{Lemma 1}
		Let $P(\overline{A}n,N_c)$ be the probability that $\Gamma_{n,N_c}\in \overline{A}$ then
		$$\lim_{n\rightarrow +\infty}P(\overline{A},n,N_c)=0$$
		That is almost all large graphs $\Gamma_{n,N_c}$ are in $A$. 
	\end{block}
\end{frame}

\begin{frame}{Proof Outline for Lemma 1}
	Let $E_M$ be the class of graphs whose largest connected component is of order at least $M$. Let $\overline{E_M}$ be the complement. Let $\mathcal{N}(\overline{E_M},n,N_c)$ be the number of graphs $\Gamma_{n,N_c}$in  $\overline{E_M}$. 
	
	$$\mathcal{N}(\overline{E_M},n,N_c)\leq \sum_{M<s<n-\frac{2N_c}{n}}{n\choose s}{{n\choose 2}-s(n-s)\choose N_c} $$
	
	Now through some ``elementary" estimations
	
	$$P(\overline{E_M},n,N_c)\leq \sum_{s>\frac{2N_c}{n}}\frac{e^{(3-2c)s}}{s!}+\sum_{s>M}\frac{e^{(3-2c)s}}{s!}$$
	 
	so $P(\overline{E_{\log\log n}},n,N_c)\rightarrow 0 $ as $n\rightarrow +\infty$. 
\end{frame}

\begin{frame}{Proof Outline for Lemma 1}
	If almost all graphs $\Gamma_{n,N_c}$ are in $E_{\log\log n}$ then we can it will be sufficient to prove that $P(\Gamma_{n,N_c}\in \overline{A}\cap E_{\log\log n})\rightarrow 0 $. 
	
	Through careful enumeration we get 
	$$P(\Gamma_{n,N_c}\in \overline{A}\cap E_{\log\log n})\leq \sum_{s=2}^{\log\log n} {n\choose s}\left(\sum_{r=1}^{s\choose 2}{{s\choose 2}\choose r}\frac{{{(n-s)\choose 2}\choose N_c-r}}{{{n\choose 2}\choose N_c}}\right)$$
	
	and by the same estimates as before we get
	$$P(\Gamma_{n,N_c}\in \overline{A}\cap E_{\log\log n})\leq\frac{e^{e^{-2c}}e^{\frac{1}{2}(\log\log n)^2}}{n}$$
	which completes the proof
\end{frame}


\begin{frame}{Probability that $\Gamma_{n,N_c}$ is connected}
	\begin{block}{Theorem 1}
		Let $P_0(n,N_c)$ denote the probability of $\Gamma_{n,N_c}$ being connected then
		$$\lim_{n\rightarrow \infty}P_0(n,N_c)=e^{-e^{-2c}}$$
		
		where $N_c=\lfloor \frac{1}{2}n\log n+ cn\rfloor$
	\end{block}
	To prove this let $\mathcal{N}_0(n,N_c)$ be the number of connected graphs $\Gamma_{n,N_c}$ (This is a subset of $A$). Further let $\mathcal{N}_0'(n,N_c)$ be the number of graphs $\Gamma_{n,N_c}$with no isolated points (Including graphs of type $\overline{A}$).
\end{frame}

\begin{frame}{Proof of theorem 1}
	We first note that
		$$\mathcal{N}_0'(n,N_c) = {{n\choose 2}\choose N_c}-\sum_{i=1}^n{n\choose i}{{n-i\choose 2}\choose N_c}$$
		which through the symmetry of ${n\choose k}$ can be written as 
		$$\mathcal{N}_0'(n,N_c) =\sum_{i=0}^n(-1)^i{n\choose i}{{n-i\choose 2}\choose N_c}$$

	This is important because the limit $\mathcal{N}_0'(n,N_c)$ is between the value of any adjacent partial sums of this series.
\end{frame}

\begin{frame}{Proof of theorem 1}
	Observe now the fact that, for any fixed $k$,
	$$\lim_{n\rightarrow +\infty}\frac{{n\choose k}{{n-k\choose2}\choose N_c}}{{{n\choose2}\choose N_c}}=\frac{e^{-2kc}}{k!}$$
	
	So when we take the limit we get
	$$\lim_{n\rightarrow \infty}\frac{\mathcal{N}_0'(n,N_c)}{{{n\choose 2}\choose N_c}}=\sum_{k=0}^\infty \frac{(-1)^ke^{-2kc}}{k!}=e^{-e^{-2c}}$$
	This last equality is simply owing to the taylor expansion of $e^x$. 
\end{frame}

\begin{frame}{Proof of theorem 1}
	We have shown that the asymptotic probability of having no isolated vertices is $e^{-e^{-2c}}$. Now we need to show that, asymptotically, almost every graph with no isolated vertices is connected.
	
	
 	Consider the graphs which have no isolated vertices but are not completely connected. This class of graphs is a subset of $\overline{A}$ (Those graphs which are not made of one connected component and some number of isolated vertices (which may be zero)). $\mathcal{N}_0'(n,N_c)$. So the probability of being in this class goes to zero asymptotically by lemma 1!
 	
 	Therefore $$\lim_{n\rightarrow \infty} P_0(n,N_c)=\lim_{n\rightarrow \infty}\frac{\mathcal{N}_0(n,N_c)}{{{n\choose 2}\choose N_c}}=e^{-e^{-2c}}$$ 
\end{frame}

\begin{frame}{Related Results}
\begin{block}{Theorem 2}
	Let $P_k(n,N_c)$ denote the probability of the greatest connected component of $\gamma_{n,N_c}$ consisting of $n-k$ vertices.
	$$\lim_{n\rightarrow \infty}P_k(n,N_c)=\frac{(e^{-2c})^ke^{-e^{-2c}}}{k!}$$
\end{block}

\begin{block}{Theorem 3}
	Let $\Pi_k(n,N_c)$ denote the probability of $\Gamma_{n,N_c}$ consisting exactly of $k+1$ disjoint connected components. 
	$$\lim_{n\rightarrow \infty}\Pi_k(n,N_c)=\frac{(e^{-2c})^ke^{-e^{-2c}}}{k!}$$
\end{block}
\end{frame}

\begin{frame}{On the Evolution of Random Graphs}
	These results are helpful and very foundational to the field of random graphs. In their next paper Erd\H{o}s and R\'enyi propose a method of evaluating the the asymptotic qualities of Random Graphs. 
	
	\begin{block}{Threshold Functions}
		Consider a set of graphs $A$. A threshold function is a function $A(n)$ such that, if $N(n)$ is the number of edges in the graph with n vertices,
		\begin{equation}
			\lim_{n\rightarrow \infty} P(\Gamma_{n,N(n)}\in A)=\begin{cases}
				0&\lim_{n\rightarrow \infty }\frac{N(n)}{A(n)}=0\\
				1&\lim_{n\rightarrow \infty }\frac{N(n)}{A(n)}=\infty 
			\end{cases}
		\end{equation} 
	\end{block}
\end{frame}

\begin{frame}{Threshold Functions}
	\begin{block}{Regular Threshold Functions}
		Consider a set of graphs $A$. A regular threshold function if a function $A(n)$ such 
		\begin{equation}
			\lim_{n\rightarrow \infty}P(\Gamma_{n,N(n)}\in A)=\begin{cases}
				0& \lim_{n\rightarrow \infty}\frac{N(n)}{A(n)} = 0\\
				F(x)&\lim_{n\rightarrow \infty}\frac{N(n)}{A(n)}=x\\
				1&\lim_{n\rightarrow \infty}\frac{N(n)}{A(n)}=\infty
			\end{cases}
		\end{equation}
		Where $F(x)$ is called the threshold distribution function and $x$ is a point of continuity of $F$. 
	\end{block}
\end{frame}

\begin{frame}{Threshold Functions}
	\begin{block}{Sharp Threshold Functions}
		Consider a set of graphs $A$. A pair of sharp threshold functions are functions $A_1(n),A_2(n)$ such that $\lim_{n\rightarrow \infty}\frac{A_2(n)}{A_1(n)}=0$ and so that
		\begin{equation}
			\lim_{n\rightarrow \infty}P(\Gamma_{n,N(n)}\in A)=\begin{cases}
				0 & \lim_{n\rightarrow \infty}\frac{N(n)-A_1(n)}{A_2(n)}=-\infty \\
				1 & \lim_{n\rightarrow \infty}\frac{N(n)-A_1(n)}{A_2(n)}=+\infty 
			\end{cases}
		\end{equation}
		If such a thing exists then $A_1$ is also a Regular Threshold Function with the threshold distribution function $F(x)=\chi_{\{x>1\}}(x)$
	\end{block}
\end{frame}

\begin{frame}{Threshold Functions}
	\begin{block}{Regular Sharp Threshold Functions}
		Consider a set of graphs $A$. A pair of sharp threshold functions are functions $A_1(n),A_2(n)$ such that $\lim_{n\rightarrow \infty}\frac{A_2(n)}{A_1(n)}=0$ and so that
		\begin{equation}
			\lim_{n\rightarrow \infty}P(\Gamma_{n,N(n)}\in A)=\begin{cases}
				0 & \lim_{n\rightarrow \infty}\frac{N(n)-A_1(n)}{A_2(n)}=-\infty \\
				G(y)&\lim_{n\rightarrow\infty}\frac{N(n)-A_1(n)}{A_2(n)}=y\\
				1 & \lim_{n\rightarrow \infty}\frac{N(n)-A_1(n)}{A_2(n)}=+\infty 
			\end{cases}
		\end{equation}
		Where $G(y)$ is called the sharp-threshold distribution function. 
	\end{block}
\end{frame}

\begin{frame}{Connectedness again}
	From the work from the previous paper we can see that, if $C$ is the set of connected graphs
	
	\begin{equation}
		\lim_{n\rightarrow \infty}P(\Gamma_{n,N(n)}\in C)=\begin{cases}
			0&\lim_{n\rightarrow}\frac{ N(n)-n}{(1/2)n\log n} = -\infty \\
			e^{-e^{-2y}}&\lim_{n\rightarrow}\frac{ N(n)-n}{(1/2)n\log n} = y\\
			1 &\lim_{n\rightarrow}\frac{ N(n)-n}{(1/2) n\log n} = +\infty \\
		\end{cases}
	\end{equation}
	The first and third equalities come from the weak contentedness result and the second equality comes from Theorem 1.  
	
	Thus we say $(\frac{1}{2}n\log n, n)$ is a pair of regular sharp threshold functions and $G(y)=e^{-e^{-2c}}$ is the sharp-threshold distribution function. 
\end{frame}

\begin{frame}{Balanced Subgraphs}
	Lets prove the existence of other threshold functions. 
	\begin{block}{Balanced Subgraphs}
		A graph $G$ is balanced if for all subgraphs $H\subseteq G$, the degree of $H$ is no greater than the degree of $G$ 
		
		(Degree of a graph is the mean of all degrees of the vertices). 
	\end{block} 
	\begin{block}{Theorem 3}
		Let $K\geq 2$ and $l \in [k-1,{k\choose 2}]$ be positive integers. Let $\mathcal{B}_{k,l}$ be a non empty set of connected balanced graphs consisting of $k$ points and $l$ edges. The Threshold function for the property that a random Graph contains at least one subgraph isomorphic with an element of $\mathcal{B}_{k,l}$ is $A(n)=n^{2-\frac{k}{l}}$
	\end{block} 
\end{frame}
\begin{frame}{Proof of Theorem 3}
	This is an undeniably difficult proof but we will make an attempt! Let $B_{k,l}$ be the number of graphs in $\mathcal{B}_{k,l}$ formed from $k$ labeled points. Let $P_{n,N}(\mathcal{B}_{k,l})$ be the probability that a random graph $\Gamma_{n,N}$ has a subgraph isomorphic to a graph in $\mathcal{B}_{k,l}$. Clearly
	$$P_{n,N}(\mathcal{B}_{k,l})\leq {n\choose k}B_{k,l}\frac{{{n\choose 2}-l\choose N-l}}{{{n\choose 2}\choose N}} = \mathcal{O}\left(\frac{N^l}{n^{2l-k}}\right)$$
	
	There are ${n\choose k}$ ways to pick $k$ vertices, $B_{k,l}$ isomorphisms to possibly achieve and ${{n-2\choose l}\choose N-l}$ ways to arrange the remaining edges.
\end{frame}

\begin{frame}{Proof of Theorem 3}
	$$P_{n,N}(\mathcal{B}_{k,l})\leq \mathcal{O}\left(\frac{N^l}{n^{2l-k}}\right)$$
	If $\lim_{n\rightarrow \infty}\frac{N(n)}{n^{2-\frac{k}{l}}}=0$ (that is $N(n)=o(n^{2-\frac{k}{l}})$) then clearly $P_{n,N(n)}(\mathcal{B}_{k,l})\rightarrow 0$. This means that surely $n^{2-\frac{k}{l}}$ is, at least, a lower threshold function. If edges are added slower than this the probability is question goes to zero.  
\end{frame}
\begin{frame}{Proof of Theorem 3}
	To prove that is also an upper threshold function we will have to consider the mean and variance of the number of subgraphs of $K_n$ ($[K_n]$)  which are in $\mathcal{B}_{k,l}$. 
	
	For any $S\in \mathcal{B}_{k,l}\cap [K_n]$, let $\epsilon(S)$ be the random variable which is $1$ if $\Gamma_{n,N}$ is a supergraph of $S$ and 0 if not.
	
	$$\mathbb{E}\left[\sum_{S\in \mathcal{B}_{k,l}\cap [K_n]} \epsilon(S)\right]=\sum_{S\in \mathcal{B}_{k,l}\cap [K_n]}\mathbb{E}\left[\varepsilon(S)\right]=B_{k,l}{n\choose k}\frac{{{n\choose 2}-1\choose N-l}}{{{n\choose 2}\choose N}}$$ 
\end{frame}

\begin{frame}{Proof of Theorem 3}
	Let $\omega:=\frac{N}{n^{2-\frac{k}{l}}}$. We use the approximation 
	$${n\choose k}\frac{{{n\choose 2}-1\choose N-l}}{{{n\choose 2}\choose N}}\sim \frac{(2N)^l}{k!n^{2l-k}}=\frac{(2\omega)^l}{k!}$$
	
	Then through some tedious calculations we see that
	$$\mathbb{V}\left[\sum_{s\in\mathcal{B}_{k,l}\cap [K_n]}\varepsilon(S)\right]=\mathcal{O}\left(\frac{\left(\sum_{S\in \mathcal{B}_{k,l}\cap [K_n]}\mathbb{E}\left[\varepsilon(S)\right]\right)^2}{\omega}\right)$$
\end{frame}

\begin{frame}{Proof of Theorem 3}
	Now it will be helpful to compute the following probability
	\begin{equation}
			P\left[\sum_{S\in \mathcal{B}_{k,l}\cap [K_n]}\epsilon(S)\leq \frac{1}{2}\sum_{S\in \mathcal{B}_{k,l}\cap [K_n]}\mathbb{E}[\epsilon(S)]\right]
	\end{equation}
	we can rearrange this to be 
	\begin{equation} 
	\begin{split} 
		P\left[\bigg|\sum_{S\in \mathcal{B}_{k,l}\cap [K_n]}\epsilon(S)-\mathbb{E}\left[\sum_{S\in \mathcal{B}_{k,l}\cap [K_n]}\epsilon(S)\right]\bigg|\geq \frac{1}{2}\sum_{S\in \mathcal{B}_{k,l}\cap [K_n]}\mathbb{E}\left[\epsilon(S)\right]\right]
	\end{split}
\end{equation}
\end{frame}
\begin{frame}{Proof of Theorem 3}
	\begin{block}{Chebyshev's Inequality}
		$$P(|X-\mu|\geq k\sigma)\leq \frac{1}{k^2}$$
		where $X$ is a random variable with expectation $\mu$ and variance $\sigma^2$, and $k$ is any constant.
	\end{block}
	Using the above inequality and the last equation from the previous slide we can show that
	\begin{equation}
			P\left[\sum_{S\in \mathcal{B}_{k,l}\cap [K_n]}\epsilon(S)\leq \frac{1}{2}\sum_{S\in \mathcal{B}_{k,l}\cap [K_n]}\mathbb{E}[\epsilon(S)]\right]\leq\mathcal{O}(\frac{1}{\omega})
	\end{equation}
	which means that if $\omega \rightarrow \infty$  then not only will $\epsilon(S)=1$ for some $S\in \mathcal{B}_{k,l}\cap [K_n]$ almost surely but indeed there will be infinitely many $S$ for which $\epsilon(S)=1$.
\end{frame}

\begin{frame}{Corollaries}
	\begin{block}{Corollary 1}
		The threshold function for the property that the random graph contains a sub graph which is a tree of order $k$ is $N(n)=n^\frac{k-2}{k-1}$
	\end{block}
	\begin{block}{Corollary 2}
		The threshold function for the property that a graph contains a connected subgraph $C_k$ of order is  $N(n)=n$ for any $k$
	\end{block}
	\begin{block}{Corollary 3}
		The threshold function for the property that a graph contains a complete subgraph of order $k\geq 2$ is $N(n)=n^{2(1-\frac{1}{k-1})}$
	\end{block}
\end{frame}

\begin{frame}{Other Results}
	Erd\H{o}s and R\'enyi go on to derive more threshold functions and regular threshold functions with corresponding threshold distribution functions. 
	
	\begin{block}{Theorem 4}
		Let $A(n)$ be the threshold function for Trees from Corollary 1. If $\lim \frac{N(n)}{A(n)}\rightarrow \rho>0$ and $\tau_k$ denotes the number of isolated trees of order $k$ in $\Gamma_{n,N(n)}$ then 
		$$\lim_{n\rightarrow \infty}P(\tau_k=j)=\frac{\lambda ^ke^{-\lambda}}{j!}$$ where $\lambda = \frac{(2\rho)^{k-1}k^{k-2}}{k!}$. 
	\end{block}
\end{frame}

\begin{frame}{Other Results}
	Erd\H{o}s and R\'enyi go on to derive more threshold functions and regular threshold functions with corresponding threshold distribution functions. 
	
	\begin{block}{Theorem 5}
		Suppose that $\lim\frac{N(n)}{n}=c>0$. Let $\gamma_k$ denote the number of cycles of order $k$ contained in $\Gamma_{n,N}$. In this case 
		$$\lim_{n\rightarrow \infty}P(\gamma_k=j)=\frac{\lambda^je^{-\lambda}}{j!}$$ where $\lambda = \frac{(2c)^k}{2k}$ 
	\end{block}
\end{frame}

\end{document}
